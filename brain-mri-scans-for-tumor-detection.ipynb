{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip uninstall opencv-python-headless -y\n#!pip uninstall opencv-contrib-python-headless -y\n#!pip install opencv-contrib-python","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.331368Z","iopub.execute_input":"2022-10-07T16:20:46.331817Z","iopub.status.idle":"2022-10-07T16:20:46.336696Z","shell.execute_reply.started":"2022-10-07T16:20:46.33178Z","shell.execute_reply":"2022-10-07T16:20:46.335255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, fapt install lynxilenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-07T16:20:46.351158Z","iopub.execute_input":"2022-10-07T16:20:46.352016Z","iopub.status.idle":"2022-10-07T16:20:46.358355Z","shell.execute_reply.started":"2022-10-07T16:20:46.351981Z","shell.execute_reply":"2022-10-07T16:20:46.35712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Workflow\n1. Preprocessing &  Plot images\n2. Convert images into desired shape and size and format. for a particular `Model`\n3. Create Labels of Yes or no for Images as per ID\n4. Train the model.\n5. Make Prediction after Train Test Split\n________________________________________\n* 6. Transform images!!! \n* 7. Identify contours and make bounding boxes.\n* 8. feed bounding boxes to another model.\n* 9. find Similarity index.\n* 10. Check accuracy and precision.\n\n____________________________","metadata":{"execution":{"iopub.status.busy":"2022-09-28T08:27:04.861469Z","iopub.execute_input":"2022-09-28T08:27:04.861972Z","iopub.status.idle":"2022-09-28T08:27:04.872092Z","shell.execute_reply.started":"2022-09-28T08:27:04.861931Z","shell.execute_reply":"2022-09-28T08:27:04.869311Z"}}},{"cell_type":"markdown","source":"###  Details of Workflow\n1. Preprocessing &  Plot images : \n`Resize, reshape and convert into grayscale and save accordingly.`\n\n2. Use *GLCM* to identify features\n3. Create Labels of Yes or no for Images as per ID\n4. Train the model.\n5. Make Prediction after Train Test Split","metadata":{"execution":{"iopub.status.busy":"2022-09-28T07:31:47.631524Z","iopub.execute_input":"2022-09-28T07:31:47.632075Z","iopub.status.idle":"2022-09-28T07:31:47.641989Z","shell.execute_reply.started":"2022-09-28T07:31:47.632029Z","shell.execute_reply":"2022-09-28T07:31:47.640228Z"}}},{"cell_type":"code","source":"fno=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/brain-mri-images-for-brain-tumor-detection/no'):\n    for filename in filenames:\n        a= os.path.join(dirname, filename)\n        fno.append(a)\nlen(fno),fno[1]        ","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.381064Z","iopub.execute_input":"2022-10-07T16:20:46.382191Z","iopub.status.idle":"2022-10-07T16:20:46.394009Z","shell.execute_reply.started":"2022-10-07T16:20:46.382144Z","shell.execute_reply":"2022-10-07T16:20:46.392724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This might be visible","metadata":{}},{"cell_type":"code","source":"fyes=[]\nfor dirname, _, filenames in os.walk('/kaggle/input/brain-mri-images-for-brain-tumor-detection/yes'):\n    for filename in filenames:\n        a= os.path.join(dirname, filename)\n        fyes.append(a)\nlen(fyes),fyes[1]        ","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.437191Z","iopub.execute_input":"2022-10-07T16:20:46.43762Z","iopub.status.idle":"2022-10-07T16:20:46.447956Z","shell.execute_reply.started":"2022-10-07T16:20:46.437586Z","shell.execute_reply":"2022-10-07T16:20:46.446824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a data Frame with File paths and labels\n* 1 --> Yes (Presence of Tumor)\n* 0 --> No (Absence of tumor)","metadata":{}},{"cell_type":"code","source":"z = [0]* len(fno)\none = [1]*len(fyes)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.449713Z","iopub.execute_input":"2022-10-07T16:20:46.450126Z","iopub.status.idle":"2022-10-07T16:20:46.45693Z","shell.execute_reply.started":"2022-10-07T16:20:46.450073Z","shell.execute_reply":"2022-10-07T16:20:46.455602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfn = pd.DataFrame(list(zip(fno,z )),\n               columns =['filepath', 'label'])\ndfy = pd.DataFrame(list(zip(fyes,one )),\n               columns =['filepath', 'label'])\n\ndf = dfn.append(dfy,ignore_index = True )\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.491587Z","iopub.execute_input":"2022-10-07T16:20:46.492012Z","iopub.status.idle":"2022-10-07T16:20:46.506521Z","shell.execute_reply.started":"2022-10-07T16:20:46.491977Z","shell.execute_reply":"2022-10-07T16:20:46.505239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a shuffeled Data Frame\n#####dfs = df.sample(frac=1,ignore_index = True)\n\n\n#######dfs.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T13:39:10.69203Z","iopub.execute_input":"2022-10-07T13:39:10.692533Z","iopub.status.idle":"2022-10-07T13:39:10.707533Z","shell.execute_reply.started":"2022-10-07T13:39:10.692483Z","shell.execute_reply":"2022-10-07T13:39:10.706125Z"}}},{"cell_type":"markdown","source":"# Function to Resize all the images","metadata":{}},{"cell_type":"code","source":"\nimg = Image.open(fno[2])\na = np.asarray(img)\n\ndf1 = []\nfor r in range (len(fno)):\n    img = Image.open(fno[r])\n    img= img.resize((224,224))\n    a=np.asarray(img)\n    df1.append(a)\n    \nfor r in range(len(fyes)):\n    img=Image.open(fyes[r])\n    img=img.resize((224,224))\n    a= np.asarray(img)\n    df1.append(a)\n    \ndf[\"Imagearr\"] = df1","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:46.551398Z","iopub.execute_input":"2022-10-07T16:20:46.551868Z","iopub.status.idle":"2022-10-07T16:20:48.25965Z","shell.execute_reply.started":"2022-10-07T16:20:46.551831Z","shell.execute_reply":"2022-10-07T16:20:48.258476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Converting Image from BRG to Gray","metadata":{"execution":{"iopub.status.busy":"2022-10-02T12:38:29.263874Z","iopub.execute_input":"2022-10-02T12:38:29.264356Z","iopub.status.idle":"2022-10-02T12:38:29.26937Z","shell.execute_reply.started":"2022-10-02T12:38:29.264316Z","shell.execute_reply":"2022-10-02T12:38:29.268503Z"}}},{"cell_type":"code","source":"import cv2\no = df.Imagearr[3]\nog = cv2.cvtColor(o,cv2.COLOR_BGR2GRAY)\nImage.fromarray(o)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:48.262214Z","iopub.execute_input":"2022-10-07T16:20:48.262875Z","iopub.status.idle":"2022-10-07T16:20:48.283687Z","shell.execute_reply.started":"2022-10-07T16:20:48.262839Z","shell.execute_reply":"2022-10-07T16:20:48.282511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image.fromarray(o)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:48.285038Z","iopub.execute_input":"2022-10-07T16:20:48.285399Z","iopub.status.idle":"2022-10-07T16:20:48.305015Z","shell.execute_reply.started":"2022-10-07T16:20:48.285367Z","shell.execute_reply":"2022-10-07T16:20:48.303835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Be carefull Run only once\n\ndf[\"GLCM-Contrast-1\"] = ''\ndf[\"GLCM-Contrast-2\"] = ''\ndf[\"GLCM-Contrast-3\"] = ''\ndf[\"GLCM-Contrast-4\"] = ''\n\ndf[\"GLCM-Dissimilarity-1\"] =''\ndf[\"GLCM-Dissimilarity-2\"] =''\ndf[\"GLCM-Dissimilarity-3\"] =''\ndf[\"GLCM-Dissimilarity-4\"] =''\n    \ndf[\"GLCM-Homogeneity-1\"]=''\ndf[\"GLCM-Homogeneity-2\"]=''\ndf[\"GLCM-Homogeneity-3\"]=''\ndf[\"GLCM-Homogeneity-4\"]=''\n    \ndf[\"GLCM-Energy-1\"]=''\ndf[\"GLCM-Energy-2\"]=''\ndf[\"GLCM-Energy-3\"]=''\ndf[\"GLCM-Energy-4\"]=''\n\ndf[\"GLCM-Correlation-1\"] =''\ndf[\"GLCM-Correlation-2\"] =''\ndf[\"GLCM-Correlation-3\"] =''\ndf[\"GLCM-Correlation-4\"] =''\n\ndf[\"GLCM-ASM-1\"]=''\ndf[\"GLCM-ASM-2\"]=''\ndf[\"GLCM-ASM-3\"]=''\ndf[\"GLCM-ASM-4\"]=''\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:48.307917Z","iopub.execute_input":"2022-10-07T16:20:48.30902Z","iopub.status.idle":"2022-10-07T16:20:48.329798Z","shell.execute_reply.started":"2022-10-07T16:20:48.308969Z","shell.execute_reply":"2022-10-07T16:20:48.328416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:48.331888Z","iopub.execute_input":"2022-10-07T16:20:48.332611Z","iopub.status.idle":"2022-10-07T16:20:59.869465Z","shell.execute_reply.started":"2022-10-07T16:20:48.332558Z","shell.execute_reply":"2022-10-07T16:20:59.868297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GLCM\nA statistical method of examining texture that considers the spatial relationship of pixels is the gray-level co-occurrence matrix (GLCM), also known as the gray-level spatial dependence matrix. The GLCM functions characterize the texture of an image by calculating how often pairs of pixel with specific values and in a specified spatial relationship occur in an image, creating a GLCM, and then extracting statistical measures from this matrix. (The texture filter functions, described in Calculate Statistical Measures of Texture cannot provide information about shape, that is, the spatial relationships of pixels in an image.)\n\nAfter you create the GLCMs using graycomatrix, you can derive several statistics from them using graycoprops. These statistics provide information about the texture of an image.\n\n* **greycomatrix** - calculate the grey-level co-occurrence matrix\n* **greycoprops** - calculate texture properties of a GLCM\n\nTexture properties can be \n1. **Contrast** - Measures the local variations in the gray-level co-occurrence matrix.\n\n2. **Correlation** - Measures the joint probability occurrence of the specified pixel pairs.\n\n3. **Energy** - Provides the sum of squared elements in the GLCM. Also known as uniformity or the angular second moment.\n\n4. **Homogeneity** - Measures the closeness of the distribution of elements in the GLCM to the GLCM diagonal.\n","metadata":{}},{"cell_type":"markdown","source":"## Overall function to add GLCM data to the data frame.","metadata":{}},{"cell_type":"markdown","source":"1. function takes image arrage as an input\n2. the image is converted into gray from BGR\n3. this image is fed to the glcm function\n4. outputs of the GLCM function are assigned to the columns of DF\n","metadata":{}},{"cell_type":"code","source":"def fxnglcm(img,i):\n    from skimage.feature import greycomatrix,greycoprops\n    import skimage.feature as feature\n\n\n    graycom = feature.graycomatrix(img, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n\n\n    c = feature.graycoprops(graycom, 'contrast')\n    d = feature.graycoprops(graycom, 'dissimilarity')\n    h = feature.graycoprops(graycom, 'homogeneity')\n    e = feature.graycoprops(graycom, 'energy')\n    corr = feature.graycoprops(graycom, 'correlation')\n    ASM = feature.graycoprops(graycom, 'ASM')\n    c = np.squeeze(c)\n    d = np.squeeze(d)\n    h = np.squeeze(h)\n    e = np.squeeze(e)\n    corr = np.squeeze(corr)\n    asm = np.squeeze(ASM)\n    \n    df[\"GLCM-Contrast-1\"][i] = c[0]\n    df[\"GLCM-Contrast-2\"][i] = c[1]\n    df[\"GLCM-Contrast-3\"][i] = c[2]\n    df[\"GLCM-Contrast-4\"][i] = c[3]\n\n    df[\"GLCM-Dissimilarity-1\"][i] =d[0]\n    df[\"GLCM-Dissimilarity-2\"][i] =d[1]\n    df[\"GLCM-Dissimilarity-3\"][i] =d[2]\n    df[\"GLCM-Dissimilarity-4\"][i] =d[3]\n    \n    df[\"GLCM-Homogeneity-1\"][i] =h[0]\n    df[\"GLCM-Homogeneity-2\"][i]=h[1]\n    df[\"GLCM-Homogeneity-3\"][i] =h[2]\n    df[\"GLCM-Homogeneity-4\"][i] =h[3]\n    \n    df[\"GLCM-Energy-1\"][i] =e[0]\n    df[\"GLCM-Energy-2\"][i] =e[1]\n    df[\"GLCM-Energy-3\"][i] =e[2]\n    df[\"GLCM-Energy-4\"][i] =e[3]\n\n    df[\"GLCM-Correlation-1\"][i] =corr[0]\n    df[\"GLCM-Correlation-2\"][i] =corr[1]\n    df[\"GLCM-Correlation-3\"][i] =corr[2]\n    df[\"GLCM-Correlation-4\"][i] =corr[3]\n\n    df[\"GLCM-ASM-1\"][i] =asm[0]\n    df[\"GLCM-ASM-2\"][i] =asm[1]\n    df[\"GLCM-ASM-3\"][i] =asm[2]\n    df[\"GLCM-ASM-4\"][i] =asm[3]\n    \n    \n    \n    return \n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:59.870826Z","iopub.execute_input":"2022-10-07T16:20:59.871185Z","iopub.status.idle":"2022-10-07T16:20:59.887698Z","shell.execute_reply.started":"2022-10-07T16:20:59.871153Z","shell.execute_reply":"2022-10-07T16:20:59.886283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Overall function\n","metadata":{}},{"cell_type":"code","source":"def glcmfiller(imgarr,i):\n    import cv2\n    if imgarr.shape !=(224, 224):\n        og = cv2.cvtColor(imgarr,cv2.COLOR_BGR2GRAY)\n        fxnglcm(og,i)\n    else:\n        fxnglcm(imgarr,i)\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:59.889158Z","iopub.execute_input":"2022-10-07T16:20:59.889645Z","iopub.status.idle":"2022-10-07T16:20:59.911004Z","shell.execute_reply.started":"2022-10-07T16:20:59.88961Z","shell.execute_reply":"2022-10-07T16:20:59.909841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(253)):\n    glcmfiller(df.loc[i,\"Imagearr\"],i)","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:20:59.912253Z","iopub.execute_input":"2022-10-07T16:20:59.913101Z","iopub.status.idle":"2022-10-07T16:21:13.540974Z","shell.execute_reply.started":"2022-10-07T16:20:59.913062Z","shell.execute_reply":"2022-10-07T16:21:13.539413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:29:03.816515Z","iopub.execute_input":"2022-10-07T16:29:03.816948Z","iopub.status.idle":"2022-10-07T16:29:24.333814Z","shell.execute_reply.started":"2022-10-07T16:29:03.816913Z","shell.execute_reply":"2022-10-07T16:29:24.332869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exporting Data Frame to Excel","metadata":{}},{"cell_type":"code","source":"df.to_excel(\"./glcm.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:13.542613Z","iopub.execute_input":"2022-10-07T16:21:13.54309Z","iopub.status.idle":"2022-10-07T16:21:13.838471Z","shell.execute_reply.started":"2022-10-07T16:21:13.543043Z","shell.execute_reply":"2022-10-07T16:21:13.837245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Detection \n","metadata":{}},{"cell_type":"markdown","source":"### Entropy","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:13.841684Z","iopub.execute_input":"2022-10-07T16:21:13.842023Z","iopub.status.idle":"2022-10-07T16:21:13.848329Z","shell.execute_reply.started":"2022-10-07T16:21:13.841994Z","shell.execute_reply":"2022-10-07T16:21:13.847009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.filters.rank import entropy\nfrom skimage.morphology import disk\n\nentropy_img = entropy(og,disk(2))\n\nfig = plt.figure(figsize = (12,12)) \nax1 = fig.add_subplot(121)# left side\nax2 = fig.add_subplot(122)\n\nax1.imshow(entropy_img)\nax2.imshow(og)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:13.850149Z","iopub.execute_input":"2022-10-07T16:21:13.850629Z","iopub.status.idle":"2022-10-07T16:21:14.378006Z","shell.execute_reply.started":"2022-10-07T16:21:13.850577Z","shell.execute_reply":"2022-10-07T16:21:14.377101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gaussian Filter\nBasically Blurs the image","metadata":{}},{"cell_type":"code","source":"from scipy import ndimage as nd\nfrom scipy import misc\n\nfig = plt.figure(figsize = (12,12))\nplt.gray()  # show the filtered result in grayscale\nax1 = fig.add_subplot(121) # On the Left\nax2 = fig.add_subplot(122) # Right Side\ngaussian_img = nd.gaussian_filter(og,sigma = 1)\nax1.imshow(gaussian_img)\nax2.imshow(og)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:14.37942Z","iopub.execute_input":"2022-10-07T16:21:14.37979Z","iopub.status.idle":"2022-10-07T16:21:14.796401Z","shell.execute_reply.started":"2022-10-07T16:21:14.379757Z","shell.execute_reply":"2022-10-07T16:21:14.79525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sobel Filter\n\nHelps to enhance the edges","metadata":{}},{"cell_type":"code","source":"from skimage.filters import sobel\n\nsobel_img = sobel(og)\n\nfig = plt.figure(figsize = (12,12))\n  # show the filtered result in grayscale\nax1 = fig.add_subplot(121)# left side\nax2 = fig.add_subplot(122)\n\nax1.imshow(sobel_img)\nax2.imshow(og)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:14.79803Z","iopub.execute_input":"2022-10-07T16:21:14.798674Z","iopub.status.idle":"2022-10-07T16:21:15.672877Z","shell.execute_reply.started":"2022-10-07T16:21:14.798639Z","shell.execute_reply":"2022-10-07T16:21:15.671667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Laplace Filter","metadata":{}},{"cell_type":"code","source":"from scipy.ndimage import laplace\n\nlaplace_img = laplace(og)\nfig = plt.figure(figsize = (12,12))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.imshow(laplace_img)\nax2.imshow(og)\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:15.674222Z","iopub.execute_input":"2022-10-07T16:21:15.674592Z","iopub.status.idle":"2022-10-07T16:21:16.177609Z","shell.execute_reply.started":"2022-10-07T16:21:15.674554Z","shell.execute_reply":"2022-10-07T16:21:16.176403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gabor Filter\nGabor filter is a linear filter with a Gaussian kernel which is modulated by a sinusoidal plane wave. Frequency and orientation representations of the Gabor filter are similar to those of the human visual system. Gabor filter banks are commonly used in computer vision and image processing. They are especially suitable for edge detection and texture classification.","metadata":{}},{"cell_type":"code","source":"from skimage.filters import gabor\nfrom skimage import io\n\nreal,gabor_img = gabor(og,frequency = 0.9)\n\nfig = plt.figure(figsize = (12,12))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.imshow(gabor_img)\nax2.imshow(og)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:16.179251Z","iopub.execute_input":"2022-10-07T16:21:16.180246Z","iopub.status.idle":"2022-10-07T16:21:16.985129Z","shell.execute_reply.started":"2022-10-07T16:21:16.180206Z","shell.execute_reply":"2022-10-07T16:21:16.983842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hessian\nFilter an image with the Hybrid Hessian filter.\n\nThis filter can be used to detect continuous edges, e.g. vessels, wrinkles, rivers. It can be used to calculate the fraction of the whole image containing such objects.","metadata":{}},{"cell_type":"code","source":"from skimage.filters import hessian\n\nhessian_img = hessian(og,sigmas = range(1,100,1))\nfig = plt.figure(figsize = (12,12))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.imshow(hessian_img)\nax2.imshow(og)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:16.986452Z","iopub.execute_input":"2022-10-07T16:21:16.986869Z","iopub.status.idle":"2022-10-07T16:21:21.203874Z","shell.execute_reply.started":"2022-10-07T16:21:16.986834Z","shell.execute_reply":"2022-10-07T16:21:21.202632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prewitt\nFind the edge magnitude using the Prewitt transform.","metadata":{}},{"cell_type":"code","source":"from skimage.filters import prewitt\n\nprewitt_img = prewitt(og)\nfig = plt.figure(figsize = (12,12))\nax1 = fig.add_subplot(121)\nax2 = fig.add_subplot(122)\n\nax1.imshow(prewitt_img)\nax2.imshow(og)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-07T16:21:21.205396Z","iopub.execute_input":"2022-10-07T16:21:21.206319Z","iopub.status.idle":"2022-10-07T16:21:21.615923Z","shell.execute_reply.started":"2022-10-07T16:21:21.206281Z","shell.execute_reply":"2022-10-07T16:21:21.614705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}